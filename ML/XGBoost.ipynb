{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "elii_W4VJ-fF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/bank_marketing/bank/bank-additional-full.csv',sep=';')"
      ],
      "metadata": {
        "id": "pFVsFY8sVz4a"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ÌÉÄÍ≤ü ÎùºÎ≤®ÎßÅ\n",
        "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
        "# 'job' Ïª¨ÎüºÏóêÏÑú ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
        "df = pd.get_dummies(df, columns=['job'], drop_first=False)\n",
        "# 'marital' Ïª¨ÎüºÏóêÏÑú ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
        "df = pd.get_dummies(df, columns=['marital'], drop_first=False)\n",
        "# OrdinalEncoder ÏÇ¨Ïö© (ÏàúÏÑú ÏßÄÏ†ï)\n",
        "encoder_edu = OrdinalEncoder(categories=[['unknown', 'illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'university.degree', 'professional.course']])\n",
        "df['education'] = encoder_edu.fit_transform(df[['education']])\n",
        "df['education'] = df['education'].astype(int)\n",
        "# 'yes' 1Ïù∏ ÏÇ¨ÎûåÏù¥ 3Î™Ö, Ïª¨Îüº ÏÇ¨Ïö© X\n",
        "df = df.drop(columns=['default'])\n",
        "# 'housing' Ïª¨ÎüºÏóêÏÑú ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
        "df = pd.get_dummies(df, columns=['housing'], drop_first=False)\n",
        "# 'loan' Ïª¨ÎüºÏóêÏÑú ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
        "df = pd.get_dummies(df, columns=['loan'], drop_first=False)\n",
        "# 'contact' Ïª¨ÎüºÏóêÏÑú ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
        "df['contact'] = df['contact'].map({'cellular': 1, 'telephone': 0})\n",
        "# 'month' Ïª¨ÎüºÏùÑ OrdinalÎ°ú Î≥ÄÌôò\n",
        "month_mapping = {\n",
        "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
        "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "}\n",
        "df['month'] = df['month'].replace(month_mapping)\n",
        "# day_of_week\n",
        "df = pd.get_dummies(df, columns=['day_of_week'], drop_first=False)\n",
        "# duration ÏÇ¨Ïö© X\n",
        "df = df.drop(columns=['duration'])\n",
        "# pdays -> 999Îäî 0ÏúºÎ°ú, ÎÇòÎ®∏ÏßÄ Í∞íÏùÄ 1Î°ú Ïù∏ÏΩîÎî©\n",
        "df['contacted_before'] = df['pdays'].apply(lambda x: 0 if x == 999 else 1)\n",
        "df = df.drop(columns=['pdays'])\n",
        "# poutcome\n",
        "df = pd.get_dummies(df, columns=['poutcome'], drop_first=False)\n",
        "# int -> float Ïª¨Îüº ÏßÄÏ†ï\n",
        "cols_to_convert = ['age', 'campaign', 'previous']\n",
        "# ÏßÄÏ†ïÎêú Ïª¨ÎüºÏùÑ float64Î°ú Î≥ÄÌôò\n",
        "df[cols_to_convert] = df[cols_to_convert].astype('float64')\n",
        "# StandardScaler Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
        "scaler = StandardScaler()\n",
        "cols_to_scaling = ['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
        "# ÏßÄÏ†ïÎêú Ïª¨ÎüºÎì§Ïóê ÎåÄÌï¥ Ïä§ÏºÄÏùºÎßÅ\n",
        "df[cols_to_scaling] = scaler.fit_transform(df[cols_to_scaling])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7glYrA3aS0n",
        "outputId": "43e3133f-6869-450e-b4bb-9cbe885bc5a5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-c056819daa7e>:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['month'] = df['month'].replace(month_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns='y')\n",
        "y = df['y']"
      ],
      "metadata": {
        "id": "S-9BYrTCazN-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.3, random_state=42, stratify=y)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXXI0tePazLa",
        "outputId": "2c5d544f-6e01-43f2-ea14-746912a5c1ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28831, 42) (12357, 42) (28831,) (12357,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GWGLdFbFaSid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(y_true, y_pred, y_prob):\n",
        "    print(\"\\nüìå Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(f\"‚úÖ Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"‚úÖ Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"‚úÖ Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"‚úÖ F1-score: {f1_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"‚úÖ ROC AUC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nüìå Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "R7XxQlne0o4b"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ïò§Î≤ÑÏÉòÌîå ÏóÜÏù¥"
      ],
      "metadata": {
        "id": "DNCzQGrxVOjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],            # Ìä∏Î¶¨ Í∞úÏàò\n",
        "    'max_depth': [3, 5, 8],                     # Ìä∏Î¶¨ ÍπäÏù¥\n",
        "    'learning_rate': [0.01, 0.05, 0.1],         # ÌïôÏäµÎ•†\n",
        "    'subsample': [0.8, 1.0],                    # ÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    #'colsample_bytree': [0.8, 1.0],             # Ìä∏Î¶¨Î≥Ñ ÌäπÏÑ± ÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    #'min_child_weight': [1, 5, 10]              # Î¶¨ÌîÑ ÎÖ∏Îìú ÏµúÏÜå Í∞ÄÏ§ëÏπò\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    XGBClassifier(random_state=42, tree_method='gpu_hist', gpu_id=0),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞:\", grid_search.best_params_)\n",
        "print(\"ÏµúÍ≥† ROC AUC:\", grid_search.best_score_)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred_prob = best_xgb.predict_proba(X_val)[:, 1]\n",
        "y_pred_best = best_xgb.predict(X_val)\n",
        "\n",
        "\n",
        "print_metrics(y_val,y_pred_best,y_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZT8Cz3dvarV",
        "outputId": "8f11c4ce-0237-482b-b261-667f6388ac31"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:43:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:43:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0}\n",
            "ÏµúÍ≥† ROC AUC: 0.7970746896684563\n",
            "\n",
            "üìå Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95     10965\n",
            "           1       0.68      0.23      0.35      1392\n",
            "\n",
            "    accuracy                           0.90     12357\n",
            "   macro avg       0.80      0.61      0.65     12357\n",
            "weighted avg       0.88      0.90      0.88     12357\n",
            "\n",
            "‚úÖ Accuracy: 0.9014\n",
            "‚úÖ Precision: 0.6843\n",
            "‚úÖ Recall: 0.2320\n",
            "‚úÖ F1-score: 0.3466\n",
            "‚úÖ ROC AUC: 0.8113\n",
            "\n",
            "üìå Confusion Matrix:\n",
            "[[10816   149]\n",
            " [ 1069   323]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# ÏµúÏ†Å Î™®Îç∏ Ï†ÄÏû•\n",
        "best_xgb = grid_search.best_estimator_\n",
        "with open(\"/content/drive/MyDrive/bank_marketing/model/xgb_base.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(best_xgb, model_file)"
      ],
      "metadata": {
        "id": "niZNlWCH9wfl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ïò§Î≤ÑÏÉòÌîåÎßÅ"
      ],
      "metadata": {
        "id": "QiSkAVjPVTea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('xgb', XGBClassifier(random_state=42, tree_method='gpu_hist', gpu_id=0))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'smote__sampling_strategy': [0.5, 0.7, 1.0],  # Ïò§Î≤ÑÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'xgb__n_estimators': [50, 100, 200],\n",
        "    'xgb__max_depth': [3, 5, 8],\n",
        "    'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'xgb__subsample': [0.8, 1.0],\n",
        "    #'xgb__colsample_bytree': [0.8, 1.0],\n",
        "    #'xgb__min_child_weight': [1, 5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞:\", grid_search.best_params_)\n",
        "print(\"ÏµúÍ≥† ROC AUC:\", grid_search.best_score_)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred_prob = best_xgb.predict_proba(X_val)[:, 1]\n",
        "y_pred_best = best_xgb.predict(X_val)\n",
        "\n",
        "\n",
        "print_metrics(y_val,y_pred_best,y_pred_prob)\n"
      ],
      "metadata": {
        "id": "EzCM-NE2VBkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535b6e43-a10c-4a81-e2d4-72d4652b767a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:47:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞: {'smote__sampling_strategy': 0.5, 'xgb__learning_rate': 0.05, 'xgb__max_depth': 5, 'xgb__n_estimators': 200, 'xgb__subsample': 0.8}\n",
            "ÏµúÍ≥† ROC AUC: 0.7879521436555034\n",
            "\n",
            "üìå Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95     10965\n",
            "           1       0.61      0.31      0.41      1392\n",
            "\n",
            "    accuracy                           0.90     12357\n",
            "   macro avg       0.77      0.64      0.68     12357\n",
            "weighted avg       0.88      0.90      0.88     12357\n",
            "\n",
            "‚úÖ Accuracy: 0.9001\n",
            "‚úÖ Precision: 0.6142\n",
            "‚úÖ Recall: 0.3053\n",
            "‚úÖ F1-score: 0.4079\n",
            "‚úÖ ROC AUC: 0.8040\n",
            "\n",
            "üìå Confusion Matrix:\n",
            "[[10698   267]\n",
            " [  967   425]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:47:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = grid_search.best_estimator_\n",
        "with open(\"/content/drive/MyDrive/bank_marketing/model/xgb_over.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(best_xgb, model_file)"
      ],
      "metadata": {
        "id": "zE7UxdC3-VMv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Ïñ∏ÎçîÏÉòÌîåÎßÅ"
      ],
      "metadata": {
        "id": "iC62hwT0VnJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('undersample', RandomUnderSampler(random_state=42)),\n",
        "    ('xgb', XGBClassifier(random_state=42, tree_method='gpu_hist', gpu_id=0))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'undersample__sampling_strategy': [0.5, 0.8],  # Ïñ∏ÎçîÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'xgb__n_estimators': [50, 100, 200],\n",
        "    'xgb__max_depth': [3, 5, 8],\n",
        "    'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'xgb__subsample': [0.8, 1.0],\n",
        "    #'xgb__colsample_bytree': [0.8, 1.0],\n",
        "    #'xgb__min_child_weight': [1, 5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞:\", grid_search.best_params_)\n",
        "print(\"ÏµúÍ≥† ROC AUC:\", grid_search.best_score_)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred_prob = best_xgb.predict_proba(X_val)[:, 1]\n",
        "y_pred_best = best_xgb.predict(X_val)\n",
        "\n",
        "\n",
        "print_metrics(y_val,y_pred_best,y_pred_prob)"
      ],
      "metadata": {
        "id": "T5mm_ZXPWcZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9264ee5e-93fc-4799-d358-c3ca085db6a0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞: {'undersample__sampling_strategy': 0.5, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 50, 'xgb__subsample': 1.0}\n",
            "ÏµúÍ≥† ROC AUC: 0.7937872782654777\n",
            "\n",
            "üìå Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93     10965\n",
            "           1       0.46      0.58      0.51      1392\n",
            "\n",
            "    accuracy                           0.88     12357\n",
            "   macro avg       0.70      0.75      0.72     12357\n",
            "weighted avg       0.89      0.88      0.88     12357\n",
            "\n",
            "‚úÖ Accuracy: 0.8755\n",
            "‚úÖ Precision: 0.4586\n",
            "‚úÖ Recall: 0.5812\n",
            "‚úÖ F1-score: 0.5127\n",
            "‚úÖ ROC AUC: 0.8132\n",
            "\n",
            "üìå Confusion Matrix:\n",
            "[[10010   955]\n",
            " [  583   809]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:49:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:49:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = grid_search.best_estimator_\n",
        "with open(\"/content/drive/MyDrive/bank_marketing/model/xgb_under.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(best_xgb, model_file)"
      ],
      "metadata": {
        "id": "-NRpuD3x-lOz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ïò§Î≤Ñ & Ïñ∏Îçî"
      ],
      "metadata": {
        "id": "qV5Y9eZYVuDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('undersample', RandomUnderSampler(random_state=42)),\n",
        "    ('xgb', XGBClassifier(random_state=42, tree_method='gpu_hist', gpu_id=0))\n",
        "])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'smote__sampling_strategy': [0.5, 0.7, 1.0],  # Ïò§Î≤ÑÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'undersample__sampling_strategy': [0.5, 0.8],  # Ïñ∏ÎçîÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'xgb__n_estimators': [50, 100, 200],\n",
        "    'xgb__max_depth': [3, 5, 8],\n",
        "    'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'xgb__subsample': [0.8, 1.0],\n",
        "    #'xgb__min_child_weight': [1, 5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞:\", grid_search.best_params_)\n",
        "print(\"ÏµúÍ≥† ROC AUC:\", grid_search.best_score_)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred_prob = best_xgb.predict_proba(X_val)[:, 1]\n",
        "y_pred_best = best_xgb.predict(X_val)\n",
        "\n",
        "\n",
        "print_metrics(y_val,y_pred_best,y_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTjpL7RFZXku",
        "outputId": "949fb0e0-55d4-4298-c353-08b075eccef4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "486 fits failed out of a total of 972.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "486 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/pipeline.py\", line 518, in fit\n",
            "    Xt, yt = self._fit(X, y, routed_params, raw_params=params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/pipeline.py\", line 440, in _fit\n",
            "    X, y, fitted_transformer = fit_resample_one_cached(\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/pipeline.py\", line 1336, in _fit_resample_one\n",
            "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/base.py\", line 202, in fit_resample\n",
            "    return super().fit_resample(X, y, **params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/base.py\", line 101, in fit_resample\n",
            "    self.sampling_strategy_ = check_sampling_strategy(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/utils/_validation.py\", line 571, in check_sampling_strategy\n",
            "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/imblearn/utils/_validation.py\", line 430, in _sampling_strategy_float\n",
            "    raise ValueError(\n",
            "ValueError: The specified ratio required to generate new sample in the majority class while trying to remove samples. Please increase the ratio.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.75527872 0.75610696 0.76878673 0.76919703 0.77449466 0.77498054\n",
            " 0.76907108 0.76603679 0.77371631 0.77248855 0.7812212  0.7802369\n",
            " 0.7770839  0.77026772 0.77942621 0.77516446 0.78278691 0.78003221\n",
            " 0.77394128 0.77638749 0.77844573 0.778968   0.78280737 0.78185563\n",
            " 0.7820045  0.78186951 0.78392672 0.783879   0.78704327 0.78644487\n",
            " 0.78403766 0.78126697 0.78644842 0.78349599 0.7862218  0.78451841\n",
            " 0.77706473 0.77803609 0.78158257 0.7822441  0.78510682 0.78592004\n",
            " 0.78324702 0.78360854 0.78654425 0.7866267  0.78701879 0.78749265\n",
            " 0.78319699 0.78309891 0.78359453 0.78488364 0.77402417 0.77760733\n",
            " 0.75969039 0.7556971  0.7705701  0.76723556 0.77539835 0.77469848\n",
            " 0.77033462 0.76445978 0.77375555 0.7705928  0.78028293 0.78062664\n",
            " 0.77611664 0.76889024 0.77859046 0.77358219 0.78108777 0.77683725\n",
            " 0.77547026 0.77421722 0.77833294 0.77806571 0.78181989 0.78214538\n",
            " 0.78083229 0.78117581 0.78296403 0.78465406 0.78615481 0.78707486\n",
            " 0.78200215 0.77916423 0.78301548 0.78167588 0.7825277  0.78195998\n",
            " 0.77638159 0.77651311 0.78171943 0.7796286  0.78477377 0.78455076\n",
            " 0.78264343 0.7837311  0.78487176 0.7869002  0.78447892 0.78652355\n",
            " 0.78256313 0.78198504 0.77919798 0.78234239 0.77117888 0.77584732\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.75495905 0.75391369 0.76700796 0.7666082  0.77296753 0.77281628\n",
            " 0.76203642 0.75950876 0.77045841 0.76934511 0.77842102 0.77782692\n",
            " 0.77242578 0.76596769 0.77554825 0.77282465 0.77914728 0.77718235\n",
            " 0.77450738 0.77273859 0.77475651 0.77518359 0.77907861 0.77838656\n",
            " 0.77908909 0.77867712 0.78106971 0.78039892 0.7844597  0.78415163\n",
            " 0.78015204 0.77794325 0.78210365 0.78064358 0.78182742 0.78381646\n",
            " 0.77397178 0.77370476 0.77782492 0.77912728 0.78298992 0.78305461\n",
            " 0.78046866 0.77961403 0.78354671 0.78407602 0.78568368 0.78598641\n",
            " 0.78234431 0.78077482 0.78175603 0.78273662 0.77387683 0.7765817\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:54:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞: {'smote__sampling_strategy': 0.5, 'undersample__sampling_strategy': 0.5, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 200, 'xgb__subsample': 1.0}\n",
            "ÏµúÍ≥† ROC AUC: 0.7874926459050604\n",
            "\n",
            "üìå Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95     10965\n",
            "           1       0.63      0.29      0.40      1392\n",
            "\n",
            "    accuracy                           0.90     12357\n",
            "   macro avg       0.77      0.63      0.67     12357\n",
            "weighted avg       0.88      0.90      0.88     12357\n",
            "\n",
            "‚úÖ Accuracy: 0.9006\n",
            "‚úÖ Precision: 0.6277\n",
            "‚úÖ Recall: 0.2895\n",
            "‚úÖ F1-score: 0.3963\n",
            "‚úÖ ROC AUC: 0.8037\n",
            "\n",
            "üìå Confusion Matrix:\n",
            "[[10726   239]\n",
            " [  989   403]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:54:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = grid_search.best_estimator_\n",
        "with open(\"/content/drive/MyDrive/bank_marketing/model/xgb_over+under.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(best_xgb, model_file)"
      ],
      "metadata": {
        "id": "cesz8juEVBao"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jz7t-pUVVBYg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcPW2wgJVBWK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ÏûÑÏãú"
      ],
      "metadata": {
        "id": "B3_k977x4oYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],            # Ìä∏Î¶¨ Í∞úÏàò\n",
        "    'max_depth': [3, 5, 8],                     # Ìä∏Î¶¨ ÍπäÏù¥\n",
        "    'learning_rate': [0.01, 0.05, 0.1],         # ÌïôÏäµÎ•†\n",
        "    'subsample': [0.8, 1.0],                    # ÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'colsample_bytree': [0.8, 1.0],             # Ìä∏Î¶¨Î≥Ñ ÌäπÏÑ± ÏÉòÌîåÎßÅ ÎπÑÏú®\n",
        "    'min_child_weight': [1, 5, 10]              # Î¶¨ÌîÑ ÎÖ∏Îìú ÏµúÏÜå Í∞ÄÏ§ëÏπò\n",
        "}\n",
        "\n",
        "grid_search1 = GridSearchCV(\n",
        "    XGBClassifier(random_state=42, tree_method='gpu_hist', gpu_id=0),\n",
        "    param_grid,\n",
        "    cv=2,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search1.fit(X_train, y_train)\n",
        "\n",
        "print(\"ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞:\", grid_search1.best_params_)\n",
        "print(\"ÏµúÍ≥† F1-score:\", grid_search1.best_score_)\n",
        "\n",
        "best_xgb1 = grid_search1.best_estimator_\n",
        "y_pred_prob = best_xgb1.predict_proba(X_val)[:, 1]\n",
        "y_pred_best = best_xgb1.predict(X_val)\n",
        "\n",
        "'''accuracy = accuracy_score(y_val, y_pred_best)\n",
        "precision = precision_score(y_val, y_pred_best)\n",
        "recall = recall_score(y_val, y_pred_best)\n",
        "f1 = f1_score(y_val, y_pred_best)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob)'''\n",
        "\n",
        "print_metrics(y_val,y_pred_best,y_pred_prob)\n",
        "\n",
        "'''# ÌèâÍ∞Ä ÏßÄÌëú Ï∂úÎ†•\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
        "print(\"\\nÎ∂ÑÎ•ò Î≥¥Í≥†ÏÑú:\\n\", classification_report(y_val, y_pred_best))'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ltjIp6U04qJs",
        "outputId": "73aca430-8cb7-4379-a11b-c1381a54d8cc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 324 candidates, totalling 648 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:02:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
            "ÏµúÍ≥† F1-score: 0.38577502412107584\n",
            "\n",
            "üìå Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94     10965\n",
            "           1       0.59      0.30      0.39      1392\n",
            "\n",
            "    accuracy                           0.90     12357\n",
            "   macro avg       0.75      0.63      0.67     12357\n",
            "weighted avg       0.88      0.90      0.88     12357\n",
            "\n",
            "‚úÖ Accuracy: 0.8973\n",
            "‚úÖ Precision: 0.5877\n",
            "‚úÖ Recall: 0.2960\n",
            "‚úÖ F1-score: 0.3937\n",
            "‚úÖ ROC AUC: 0.7761\n",
            "\n",
            "üìå Confusion Matrix:\n",
            "[[10676   289]\n",
            " [  980   412]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:02:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# ÌèâÍ∞Ä ÏßÄÌëú Ï∂úÎ†•\\nprint(f\"Accuracy: {accuracy:.4f}\")\\nprint(f\"Precision: {precision:.4f}\")\\nprint(f\"Recall: {recall:.4f}\")\\nprint(f\"F1 Score: {f1:.4f}\")\\nprint(f\"AUC-ROC: {roc_auc:.4f}\")\\nprint(\"\\nÎ∂ÑÎ•ò Î≥¥Í≥†ÏÑú:\\n\", classification_report(y_val, y_pred_best))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}